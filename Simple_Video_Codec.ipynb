{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4dd863f30f71e62fbcbc33c40a0b1888",
          "grade": false,
          "grade_id": "cell-7139b87bf60b734e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZEz4Xef6EpZ8"
      },
      "source": [
        "## Compression of a Video using a Color Transform, Chroma Downsampling, Block-DCT with Block-Sampling, and Motion Compensation\n",
        "\n",
        "\n",
        "- To improve compresstion performance, it also include motion compesation, for instance using the nearest neighbour approach.\n",
        "\n",
        "- For simplicity, for a size (480, 640) frame, omit the boundaries, e.g. just use the blocks 10 to 50 vertically and 10 to 60 hroizontally for motion compensation.  \n",
        "- To optimize compression rate and visual quality, for the nearest neighbour approach, find a suitable threshold (for the mae or mse) above which motion is detected, and a suitable search neighbourhood (limit the length of the motion vectors)\n",
        "- Use a Group of Pictures (GoP) sequence of I,P,I, meaning after each intra coded frame follows a predicted frame.\n",
        "- For simplicity for the predicted frames, just store the motion vectors and not the residual, and decode just from them and the previous I frame.\n",
        "- Store these in a pickle file \"encoded.pickle\" as encoded file.  \n",
        "- A corresponding decoder function \"decoder\", which takes the pickle file \"encoded.pickle\" as input and writes the decoded video in file \"decoded.mp4\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5b5a698ee48a850ee6e5812a6e83130a",
          "grade": false,
          "grade_id": "filter",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "MffrB1RPEpZ-",
        "outputId": "4027d5c0-6055-47c8-e0fe-fc0d21a04b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Done\n"
          ]
        }
      ],
      "source": [
        "#sudo apt-get install libopencv-dev python3-opencv\n",
        "#!pip3 install opencv-python\n",
        "#!pip3 install pickle5\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle5 as pickle\n",
        "import scipy.signal\n",
        "import scipy.fftpack as sft\n",
        "import numpy as np\n",
        "\n",
        "def mean_squared_error(Previous_frame, Current_frame):\n",
        "    return ((Current_frame-Previous_frame)**2).mean(axis=None)\n",
        "\n",
        "def psnr_image(encoded_plane, reference_plane):\n",
        "\n",
        "    mse = mean_squared_error(reference_plane, encoded_plane)\n",
        "    if mse == 0: \n",
        "        return np.inf\n",
        "    max_i = 255\n",
        "    psnr = 20 * np.log10(max_i) - 10 * np.log10(mse)\n",
        "    return psnr\n",
        "\n",
        "def view_as_block(img, blocksize=(8, 8), color = False):\n",
        "    if color:\n",
        "        h, w = img[:,:,0].shape[0:2]\n",
        "        for i in range(0, h-blocksize[0], blocksize[0]):\n",
        "            for j in range(0, w-blocksize[1], blocksize[1]):\n",
        "                block = img[i:i + blocksize[0], j:j + blocksize[1],:]\n",
        "                if block[:,:,0].shape == blocksize:\n",
        "                    yield i, j, block\n",
        "    else:\n",
        "        h, w = img.shape[0:2]\n",
        "        for i in range(0, h, blocksize[0]):\n",
        "            for j in range(0, w, blocksize[1]):\n",
        "                block = img[i:i + blocksize[0], j:j + blocksize[1]]\n",
        "                if block.shape == blocksize:\n",
        "                    yield i, j, block\n",
        "\n",
        "\n",
        "def search_range(i, max_i, max_distance, blocksize):\n",
        "    max_range = min(i + max_distance + int(blocksize / 2), max_i - int(blocksize / 2))\n",
        "    min_range = max(i - max_distance, 0)\n",
        "    return range(min_range, max_range)\n",
        "\n",
        "\n",
        "def compress(image):\n",
        "    factor = 4\n",
        "    size = 2\n",
        "    compressed_blocks = np.zeros(image.shape)\n",
        "    subband = np.zeros((int(image.shape[0] / factor), int(image.shape[1] / factor)))\n",
        "    for i, j, b in view_as_block(image, (8, 8)):\n",
        "        block = sft.dctn(b, norm='ortho')\n",
        "        k = int(i / factor)\n",
        "        l = int(j / factor)\n",
        "        subband[k:(k + size), l:(l + size)] = block[:size, :size]\n",
        "    return subband\n",
        "\n",
        "\n",
        "def decompress(image):\n",
        "    factor = 4\n",
        "    size = 2\n",
        "    decomp = np.zeros((image.shape[0] * factor, image.shape[1] * factor))\n",
        "\n",
        "    for i in range(0, image.shape[0], size):\n",
        "        for j in range(0, image.shape[1], size):\n",
        "            block = np.zeros((8, 8))\n",
        "            block[:size, :size] = image[i:(i + size), j:(j + size)]\n",
        "            block = sft.idctn(block, norm='ortho')\n",
        "            k = int(i * factor)\n",
        "            l = int(j * factor)\n",
        "            decomp[k:(k + 8), l:(l + 8)] = block\n",
        "    return decomp\n",
        "\n",
        "\n",
        "def exhaustive_search(prev, curr, blocksize=(8, 8), max_distance=10):\n",
        "    motion_vectors = np.zeros([curr.shape[0] // blocksize[0], curr.shape[1] // blocksize[1], 2]).astype(int)\n",
        "    for i, j, b in view_as_block(curr, blocksize=blocksize, color = True):\n",
        "        \n",
        "        bi = np.floor(i / blocksize[0]).astype(int)\n",
        "        bj = np.floor(j / blocksize[1]).astype(int)\n",
        "\n",
        "        block_results = []\n",
        "        equal_found = False\n",
        "\n",
        "        blockrange = [[10,50],[10,60]]\n",
        "        if bi in range(blockrange[0][0],blockrange[0][1]) and bj in range(blockrange[1][0],blockrange[1][1]):\n",
        "            # (ti, tj) refers to indices of the block under test\n",
        "            for ti in search_range(i, curr.shape[0], max_distance, blocksize[0]):\n",
        "                for tj in search_range(j, curr.shape[1], max_distance, blocksize[1]):\n",
        "                    # selct the block that we want to check\n",
        "                    block_to_check = prev[ti:ti + blocksize[0], tj:tj + blocksize[1]]\n",
        "                    # calculate psnr of block_to_check and block b\n",
        "                    sim = 0\n",
        "                    for c in range(3):\n",
        "                        sim += psnr_image(block_to_check[:,:,c], b[:,:,c])\n",
        "                    block_results.append((ti, tj, sim))\n",
        "\n",
        "                    if sim == np.inf or sim >= 85.5:  # here a match is found\n",
        "                        equal_found = True\n",
        "                        #print(\"found\")\n",
        "                    if equal_found:\n",
        "                        break\n",
        "                if equal_found:\n",
        "                    break\n",
        "            if sim != np.inf:\n",
        "                m = np.argmax(np.array(block_results)[:, 2])\n",
        "                ti, tj, sim = block_results[m]\n",
        "            motion_vectors[bi, bj, 0] = (i - ti) / blocksize[0]\n",
        "            motion_vectors[bi, bj, 1] = (j - tj) / blocksize[1]\n",
        "    return motion_vectors\n",
        "\n",
        "def predict_frame(prev, mv, blocksize=(8, 8)):\n",
        "    pred = prev\n",
        "    for i in range(mv.shape[0]):\n",
        "        for j in range(mv.shape[1]):\n",
        "            bi = i * blocksize[0]\n",
        "            bj = j * blocksize[1]\n",
        "            mi = bi + mv[i, j, 0]\n",
        "            mj = bj + mv[i, j, 1]\n",
        "            pred[mi:mi + blocksize[0], mj:mj + blocksize[1],:] = prev[bi:bi + blocksize[0], bj:bj + blocksize[1],:]\n",
        "    return pred\n",
        "\n",
        "\n",
        "\n",
        "#####################################################Encoder#####################################################\n",
        "\n",
        "\n",
        "\n",
        "def encoder():\n",
        "        \n",
        "    cap = cv2.VideoCapture('videorec.mp4')\n",
        "    g=open('encoded.pickle', 'wb')\n",
        "    #Prevous Y frame:\n",
        "    \n",
        "    n=0 #frame counter\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame0 = cap.read()\n",
        "        if ret==0:\n",
        "            break\n",
        "            \n",
        "        [rows,columns,d]=frame0.shape\n",
        "        #Yprev=np.zeros((rows,columns)) #memory for previous Y frame\n",
        "        #motion vectors, for each block a 2-d vector:\n",
        "        mv=np.zeros((rows//8,columns//8,2))\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "        if n % 2 == 0:\n",
        "            iframe = True;\n",
        "        else:\n",
        "            iframe = False;\n",
        "        if iframe:\n",
        "            (B, G, R) = cv2.split(frame0)\n",
        "\n",
        "            Y = 0.299 * R + 0.587 * G + 0.144 * B\n",
        "            C_b = - 0.16864 * R - 0.33107 * G + 0.49970 * B\n",
        "            C_r = 0.499813 * R - 0.418531 * G - 0.081282 * B\n",
        "            # print(C_b)\n",
        "\n",
        "            C_b_enc = C_b[::2, ::2]\n",
        "            C_r_enc = C_r[::2, ::2]\n",
        "\n",
        "            Y = compress(Y)\n",
        "            C_b_enc = compress(C_b_enc)\n",
        "            C_r_enc = compress(C_r_enc)\n",
        "\n",
        "            Y = np.int16(Y)\n",
        "            C_b_enc = np.int16(C_b_enc)\n",
        "            C_r_enc = np.int16(C_r_enc)\n",
        "\n",
        "            pickle.dump(Y, g)\n",
        "            pickle.dump(C_b_enc, g)\n",
        "            pickle.dump(C_r_enc, g)\n",
        "            prev = frame0\n",
        "        else:\n",
        "            pred = frame0\n",
        "            mv = exhaustive_search(prev, pred) + 50\n",
        "            mv = np.uint8(mv)\n",
        "            pickle.dump(mv, g)\n",
        "        print(n)\n",
        "        n += 1\n",
        "        ### End Code here\n",
        "\n",
        "    cap.release()\n",
        "    return \n",
        "\n",
        "##Decoder:#####################\n",
        "def decoder():\n",
        "    \n",
        "    g=open('encoded.pickle', 'rb')\n",
        "    height , width = (480, 640)\n",
        "    # Define the codec and create VideoWriter object\n",
        "    #fourcc = cv.CV_FOURCC(*'XVID')\n",
        "    #fourcc = cv.CV_FOURCC('D','I','V','X')\n",
        "    #fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    #Open video output file:\n",
        "    out = cv2.VideoWriter('decoded.mp4',fourcc, 20.0, (width,height))\n",
        "    n=0 #frame counter\n",
        "    while(True):\n",
        "        #load next frame from file f and \"de-pickle\" it, convert from a string back to colortransform or tensor:\n",
        "        \n",
        "        print(\"Frame= \", n)\n",
        "        #every 2nd frame is an iframe:\n",
        "        if n%2==0:\n",
        "          iframe=True;\n",
        "        else:\n",
        "          iframe=False;\n",
        "\n",
        "        #Load an encoded frame:\n",
        "        if iframe: \n",
        "            #print(\"IFrame\")\n",
        "            try:\n",
        "                Ydct=pickle.load(g)\n",
        "                if n==0:\n",
        "                    (rows, cols)=Ydct.shape #find stored video dimensions\n",
        "                    print(\"(rows, cols)=\",(rows, cols))\n",
        "                    #out = cv2.VideoWriter('decoded.mp4',fourcc, 20.0, (cols,rows)) #write to this file\n",
        "            except (EOFError):\n",
        "                break\n",
        "            DCb = pickle.load(g)\n",
        "            DCr = pickle.load(g)\n",
        "            Y = decompress(Ydct)\n",
        "            DCb = decompress(DCb)\n",
        "            DCr = decompress(DCr)\n",
        "\n",
        "            C_b = (np.repeat(np.repeat(DCb, 2, axis=0), 2, axis=1))\n",
        "            C_r = (np.repeat(np.repeat(DCr, 2, axis=0), 2, axis=1))\n",
        "\n",
        "            R = Y + 1.4025 * C_r\n",
        "            G = Y - 0.34434 * C_b - 0.7144 * C_r\n",
        "            B = Y + 1.7731 * C_b\n",
        "\n",
        "            R = np.uint8(R)\n",
        "            G = np.uint8(G)\n",
        "            B = np.uint8(B)\n",
        "            framedec = cv2.merge([B, G, R])\n",
        "            prev = framedec\n",
        "        else:\n",
        "            # print(\"PFrame\")\n",
        "            try:\n",
        "                MV = pickle.load(g)\n",
        "            except (EOFError):\n",
        "                break\n",
        "            MV = MV.astype(int) - 50\n",
        "            #print(MV)\n",
        "            pframe = predict_frame(prev, MV)\n",
        "            framedec = np.uint8(pframe)\n",
        "\n",
        "        print(\"framedec.shape=\",framedec.shape)\n",
        "        out.write(framedec)\n",
        "        n+=1\n",
        "    out.release()\n",
        "    return\n",
        "    \n",
        "print('All Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWUFBEU_EpaB"
      },
      "source": [
        "- Run the next cell to evaluate your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a27a3f438052e254ea7a94950b0b4199",
          "grade": true,
          "grade_id": "test_design",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "YVRO_Fx1EpaB",
        "outputId": "afb7e475-3b83-4efd-dbd7-0033f5d2d0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "Frame=  0\n",
            "(rows, cols)= (120, 160)\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  1\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  2\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  3\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  4\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  5\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  6\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  7\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  8\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  9\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  10\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  11\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  12\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  13\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  14\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  15\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  16\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  17\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  18\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  19\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  20\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  21\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  22\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  23\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  24\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  25\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  26\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  27\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  28\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  29\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  30\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  31\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  32\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  33\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  34\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  35\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  36\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  37\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  38\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  39\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  40\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  41\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  42\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  43\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  44\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  45\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  46\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  47\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  48\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  49\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  50\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  51\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  52\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  53\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  54\n",
            "framedec.shape= (480, 640, 3)\n",
            "Frame=  55\n",
            "Ruinning submission done. Even if the Validade Notebook passes all tests that doesn't mean that your answer is correct!\n",
            "Log Compression ratio= -1.3742324611445764\n",
            "ssim value= 0.935155\n",
            "performance= 26.680417538855423\n"
          ]
        }
      ],
      "source": [
        "#the cell will pass if no errors are raised by \"assert\", and fail otherwise\n",
        "import scipy.signal as sp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "encoder()\n",
        "decoder()\n",
        "\n",
        "print(\"Ruinning submission done. Even if the Validade Notebook passes all tests that doesn't mean that your answer is correct!\")\n",
        "#print(\"Playing Videos...\")\n",
        "#!python play_video.py 'videorec.mp4' 'decoded.mp4'\n",
        "\n",
        "compsize=os.path.getsize('encoded.pickle')\n",
        "decsize=os.path.getsize('decoded.mp4')\n",
        "logcompression=np.log(decsize/compsize)\n",
        "print(\"Log Compression ratio=\", logcompression)\n",
        "\n",
        "\n",
        "\n",
        "#\"\"\"\n",
        "#os.system('ffmpeg -i videorec.mp4 -i decoded.mp4 -filter_complex \"ssim\" -f null /dev/null &> out.txt')\n",
        "#!pwd\n",
        "#!ffmpeg -i videorec.mp4 -i decoded.mp4 -filter_complex \"ssim\" -f null /dev/null &> out.txt\n",
        "old_stdout = sys.stdout\n",
        "sys.stdout = open('out.txt', 'w')\n",
        "!ffmpeg -i videorec.mp4 -i decoded.mp4 -filter_complex \"ssim\" -f null /dev/null \n",
        "os.system(\"grep -oP '(?<=All:)[0-9.]+' out.txt > ssim.txt\")\n",
        "ssimval=np.loadtxt('ssim.txt')\n",
        "sys.stdout = old_stdout\n",
        "print(\"ssim value=\", ssimval)\n",
        "\n",
        "#performance=logcompression+0.05/(1-ssimval)\n",
        "performance=logcompression+30*ssimval\n",
        "print(\"performance=\", performance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XQI1yD0EpaD",
        "outputId": "28388603-c168-4a04-8613-bb592f601877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26.680417538855423\n"
          ]
        }
      ],
      "source": [
        "print(performance)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Simple_Video_Codec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}